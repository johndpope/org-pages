<!DOCTYPE html>
<html lang="zh-CN">
<head>
<!-- 2019-01-24 Thu 21:14 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>spark 学习</title>
<meta name="generator" content="Org mode">
<meta name="author" content="manue1">
<link rel="stylesheet" type="text/css" href="css/worg.css" />
<!-- <link rel="shortcut icon" href="http://www.langdebuqing.com/images/favicon.ico" type="image/x-icon" /> -->
</head>
<body>
<div id="preamble" class="status">
<div id="navbar">
    <ul>
        <li id="site-master"><a href="https://www.manue1.site/">Manue1's Journal</a></li>
        <li><a class="navbar-item" href="https://www.manue1.site/write.html">All Posts</a> </li>
        <li><a class="navbar-item" href="https://www.manue1.site/link.html">Links</a> </li>
        <li class="search">
            <form action="http://google.com/search" method="get" accept-charset="utf-8">
                <input type="search" id="search" name="q" autocomplete="off" maxlength="30" placeholder="Search..">
                <input type="hidden" name="q" value="site:www.manue1.com">
            </form>
        </li>
    </ul>
</div>
</div>
<div id="content">
<h1 class="title">spark 学习</h1>
<div id="table-of-contents">
<h2>&#30446;&#24405;</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgd5a4cff">1. what is spark</a></li>
<li><a href="#orgd36ee9e">2. RDD</a>
<ul>
<li><a href="#orgf4e40f1">2.1. RDD基础</a></li>
</ul>
</li>
<li><a href="#org59ba57b">3. spark use</a>
<ul>
<li><a href="#orgdf08fd5">3.1. spark base</a></li>
<li><a href="#org7a40198">3.2. spark install</a></li>
<li><a href="#org453515d">3.3. spark shell</a></li>
<li><a href="#orgc774246">3.4. idea spark scala</a></li>
<li><a href="#org06d14c5">3.5. idea spark java</a></li>
<li><a href="#org8c133c1">3.6. rdd &amp; dataframe</a></li>
</ul>
</li>
<li><a href="#org338c1ab">4. <span class="todo TODO">TODO</span> 如何转表格</a></li>
<li><a href="#org965e902">5. Spark Executor在YARN上的内存分配</a></li>
<li><a href="#org2bae758">6. 如何对spark任务调优?</a></li>
</ul>
</div>
</div>
<p>
Spark快速大数据分析[美] 卡劳（Holden Karau）<br>
</p>
<div id="outline-container-orgd5a4cff" class="outline-2">
<h2 id="orgd5a4cff"><span class="section-number-2">1</span> what is spark</h2>
<div class="outline-text-2" id="text-1">
<p>
spark 是一个用来实现快速而通用的集群计算的平台<br>
</p>
<ul class="org-ul">
<li>spark core<br></li>
<li>spark sql<br></li>
<li>spark streaming<br></li>
<li>MLlib<br></li>
<li>GraphX<br></li>
<li>集群管理器<br>
<ul class="org-ul">
<li>自带简易调度器，独立调度器<br></li>
<li>Hadoop YARN<br></li>
<li>Apache Mesos<br></li>
</ul></li>
<li>Spark的存储层次<br>
<ul class="org-ul">
<li>支持本地文件,HDFS,Hive,HBase<br></li>
<li>文件格式:文本文件,SequenceFile,Avro,Parquet<br></li>
</ul></li>
<li>shell<br>
spark shell 可用来与分布式存储在许多机器的内存或者硬盘上的数据进行交互<br>
python shell / scala shell<br></li>
<li>SparkContext<br>
每个Sparkyingy<br></li>
</ul>
</div>
</div>
<div id="outline-container-orgd36ee9e" class="outline-2">
<h2 id="orgd36ee9e"><span class="section-number-2">2</span> RDD</h2>
<div class="outline-text-2" id="text-2">
<p>
RDD(resilient distributed dataset)<br>
</p>
</div>
<div id="outline-container-orgf4e40f1" class="outline-3">
<h3 id="orgf4e40f1"><span class="section-number-3">2.1</span> RDD基础</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Spark中的RDD是一个不可变的分布式对象集合<br>
</p>
</div>
</div>
</div>

<div id="outline-container-org59ba57b" class="outline-2">
<h2 id="org59ba57b"><span class="section-number-2">3</span> spark use</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-orgdf08fd5" class="outline-3">
<h3 id="orgdf08fd5"><span class="section-number-3">3.1</span> spark base</h3>
<div class="outline-text-3" id="text-3-1">
<p>
rdd(resilient distributed dataset)<br>
</p>
</div>
</div>
<div id="outline-container-org7a40198" class="outline-3">
<h3 id="org7a40198"><span class="section-number-3">3.2</span> spark install</h3>
<div class="outline-text-3" id="text-3-2">
<p>
函数式编程<br>
shell下执行:paste<br>
</p>
</div>
</div>
<div id="outline-container-org453515d" class="outline-3">
<h3 id="org453515d"><span class="section-number-3">3.3</span> spark shell</h3>
<div class="outline-text-3" id="text-3-3">
<p>
bin/spark-shell<br>
</p>
<ul class="org-ul">
<li>创建RDD<br>
sc.parallelize()<br></li>
<li>RDD操作<br>
<ul class="org-ul">
<li>转化操作<br>
返回的是RDD<br>
map()<br>
filter()<br></li>
<li>行动操作<br>
返回结果或把结果写入外部系统的操作,返回的是其他数据类型<br></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgc774246" class="outline-3">
<h3 id="orgc774246"><span class="section-number-3">3.4</span> idea spark scala</h3>
<div class="outline-text-3" id="text-3-4">
<p>
scala 项目手动打包<br>
删除scala 和spark的包<br>
</p>

<p>
执行中 spark-submit &#x2013;class com.nti.spark.SparkTags spark_scala_jar.jar<br>
</p>

<p>
sbt 构建项目 需要等待sbt版本下载好才会生成src目录<br>
</p>
</div>
</div>

<div id="outline-container-org06d14c5" class="outline-3">
<h3 id="org06d14c5"><span class="section-number-3">3.5</span> idea spark java</h3>
<div class="outline-text-3" id="text-3-5">
<ol class="org-ol">
<li>jre 1.5 换成1.8<br></li>
</ol>
</div>
</div>
<div id="outline-container-org8c133c1" class="outline-3">
<h3 id="org8c133c1"><span class="section-number-3">3.6</span> rdd &amp; dataframe</h3>
</div>
</div>
<div id="outline-container-org338c1ab" class="outline-2">
<h2 id="org338c1ab"><span class="section-number-2">4</span> <span class="todo TODO">TODO</span> 如何转表格</h2>
<div class="outline-text-2" id="text-4">
<p>
格式	可分割	平均压缩速度	文本文件压缩效率	Hadoop压缩编解码器	纯Java实现	原生	备注<br>
gzip	否	快	高	org.apache.hadoop.io.compress.GzipCodec	是	是<br>
lzo	是（取决于所使用的库）	非常快	中等	com.hadoop.compression.lzo.LzoCodec	是	是	需要在每个节点上安装LZO<br>
bzip2	是	慢	非常高	org.apache.hadoop.io.compress.Bzip2Codec	是	是	为可分割版本使用纯Java<br>
zlib	否	慢	中等	org.apache.hadoop.io.compress.DefaultCodec	是	是	Hadoop 的默认压缩编解码器<br>
Snappy	否	非常快	低	org.apache.hadoop.io.compress.SnappyCodec	否	是	Snappy 有纯Java的移植版，但是在Spark/Hadoop中不能用<br>
</p>
</div>
</div>
<div id="outline-container-org965e902" class="outline-2">
<h2 id="org965e902"><span class="section-number-2">5</span> Spark Executor在YARN上的内存分配</h2>
<div class="outline-text-2" id="text-5">
<p>
从Spark的角度看，Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead<br>
一、ExecutorMemory<br>
ExecutorMemory为JVM进程的Java堆区域。大小通过属性spark.executor.memory设置。也可以在spark-submit命令时用参数&#x2013;executor-memory设置。<br>
</p>

<p>
用于缓存RDD数据的memoryStore位于这一区域。<br>
memoryStore占用空间的比例通过属性spark.storage.memoryFraction和spark.storage.safetyFraction控制<br>
</p>

<p>
二、MemoryOverhead<br>
</p>

<p>
MemoryOverhead是JVM进程中除Java堆以外占用的空间大小，包括方法区（永久代）、Java虚拟机栈、本地方法栈、JVM进程本身所用的内存、直接内存（Direct Memory）等。通过spark.yarn.executor.memoryOverhead设置，单位MB。<br>
</p>

<p>
三、相关问题<br>
</p>


<p>
如果用于存储RDD的空间不足，先存储的RDD的分区会被后存储的覆盖。当需要使用丢失分区的数据时，丢失的数据会被重新计算<br>
</p>

<p>
如果Java堆或者永久代的内存不足，则会产生各种OOM异常，executor会被结束。spark会重新申请一个container运行executor。失败executor上的任务和存储的数据会在其他executor上重新计算。<br>
</p>

<p>
如果实际运行过程中ExecutorMemory+MemoryOverhead之和（JVM进程总内存）超过container的容量。YARN会直接杀死container。executor日志中不会有异常记录。spark同样会重新申请container运行executor。<br>
</p>





<p>
在Java堆以外的JVM进程内存占用较多的情况下，应该将MemoryOverhead设置为一个足够大的值，应该将MemoryOverhead设置为一个足够大的值，以防JVM进程因实际占用的内存超标而被kill。如果默认值（math.max((MEMORY_OVERHEAD_FACTOR *executorMemory).toInt,MEMORY_OVERHEAD_MIN）不够大，可以通过spark.yarn.executor.memoryOverhead手动设置一个更大的值。<br>
</p>
</div>
</div>
<div id="outline-container-org2bae758" class="outline-2">
<h2 id="org2bae758"><span class="section-number-2">6</span> 如何对spark任务调优?</h2>
<div class="outline-text-2" id="text-6">
<p>
<a href="http://www.cnblogs.com/xing901022/p/6445254.html">http://www.cnblogs.com/xing901022/p/6445254.html</a><br>
</p>

<p>
调优的经验总结<br>
1 输出信息<br>
在Spark应用里面可以直接使用System.out.println把信息输出出来，系统会直接拦截out输出到spark的日志。像我们使用的yarn作为资源管理系统，在yarn的日志中就可以直接看到这些输出信息了。这在数据量很大的时候，做一些show()（默认显示20），count() 或者 take(10)的时候会很方便。<br>
</p>

<p>
2 内存不够<br>
当任务失败，收到sparkContext shutdown的信息时，基本都是执行者的内存不够。这个时候，一方面可以调大&#x2013;excutor-memory参数，另一方面还是得回去看看程序。如果受限于系统的硬件条件，无法加大内存，可以采用局部调试法，检查是在哪里出现的内存问题。比如，你的程序分成几个步骤，一步一步的打包运行，最后检查出现问题的点就可以了。<br>
</p>

<p>
3 ThreadPool<br>
线程池不够，这个是因为&#x2013;excutor-core给的太少了，出现线程池不够用的情况。这个时候就需要调整参数的配置了。<br>
</p>

<p>
4 physical memory不够<br>
</p>


<p>
这种问题一般是driver memory不够导致的，driver memory通常存储了以一些调度方面的信息，这种情况很有可能是你的调度过于复杂，或者是内部死循环导致。<br>
</p>

<p>
5 合理利用缓存<br>
在Spark的计算中，不太建议直接使用cache，万一cache的量很大，可能导致内存溢出。可以采用persist的方式，指定缓存的级别为MEMORY_AND_DISK,这样在内存不够的时候，可以把数据缓存到磁盘上。另外，要合理的设计代码，恰当地使用广播和缓存，广播的数据量太大会对传输带来压力，缓存过多未及时释放，也会导致内存占用。一般来说，你的代码在需要重复使用某一个rdd的时候，才需要考虑进行缓存，并且在不使用的时候，要及时unpersist释放。<br>
</p>

<p>
6 尽量避免shuffle<br>
这个点，在优化的过程中是很重要的。比如你需要把两个rdd按照某个key进行groupby，然后在进行leftouterjoin，这个时候一定要考虑大小表的问题。如果把大表关联到小表，那么性能很可能会很惨。而只需要简单的调换一下位置，性能就可能提升好几倍。<br>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p>
    <a href="">manue1</a> 搭建和维护，使用
    <a href="https://www.gnu.org/software/emacs/">Emacs</a>
    <a href="http://orgmode.org/">Org mode</a> 编辑和构建
</p>
<script src="http://www.langdebuqing.com/css/jquery-2.1.3.min.js"></script>
<script src="http://www.langdebuqing.com/css/main.js"></script>
</div>
</body>
</html>