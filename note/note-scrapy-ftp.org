#+TITLE:  用scrapy爬取FTP列表文件
* 用scrapy爬取FTP列表文件
** scrapy crawl ftp server
   #+BEGIN_VERSE
   最近遇到一个ftp数据源，每天需要定期到ftp服务器登录下载文件压缩列表,官方提供的[[https://github.com/scrapy/scrapy/blob/master/scrapy/core/downloader/handlers/ftp.py][FTPDownloadHandler]] 只能下载单个文件,但这里我需要下载文件目录下所有文件,这里找到一篇好[[https://gearheart.io/blog/crawling-ftp-server-with-scrapy/][文章]] ,详细的讲述了如何重写scrapy所支持的HTTP,HTTPS,FTP等下载Handler.由于作者从单个FTP文件下载，到文件夹内全部文件下载都做了详细的阐述，这里就贴出我的实现代码吧，做了些许修改
   #+END_VERSE
   1. 修改settings 文件
      #+BEGIN_SRC 
      DOWNLOAD_HANDLERS = {'ftp': 'opensource_threat_intel.ftp.FtpListingHandler'}
      #+END_SRC
   2. 创建ftp.py文件
      
      #+BEGIN_VERSE
      简单说下处理流程,scrapy调度器捕捉到为ftp协议的request的时候,会根据settings内设置的FtpListingHandler处理ftp请求,该方法的父类是官方提供的FTPDownloadHandler.重写了gotClient客户端来创建一个ftp请求客户端,如果request为spider内FileFtpRequest方法传过来的请求下载单个文件的行为,则直接使用super调用父类官方提供的下载单文件方法,此时记得在重写的build_response内给下载器返回的response也是父类_build_response返回的单个文件的数据，而不是从重写后_build_response返回的文件夹内的文件名
      #+END_VERSE
      #+BEGIN_SRC 
import json
from scrapy.core.downloader.handlers.ftp import FTPDownloadHandler
from scrapy.http import Response
from twisted.protocols.ftp import FTPFileListProtocol
from spiders.cyren_intel import FileFtpRequest, ListFtpRequest

class FtpListingHandler(FTPDownloadHandler):
    # get files list or one file
    def gotClient(self, client, request, filepath):
        # check what class sent a request
        if isinstance(request, FileFtpRequest):
            return super(FtpListingHandler, self).gotClient(
                client, request, filepath)

        protocol = FTPFileListProtocol()
        return client.list(filepath, protocol).addCallbacks(
            callback=self._build_response,
            callbackArgs=(request, protocol),
            errback=self._failed,
            errbackArgs=(request,))

    def _build_response(self, result, request, protocol):
        # get files list or one file
        self.result = result
        if isinstance(request, ListFtpRequest):
            body = json.dumps(protocol.files)
            return Response(url=request.url, status=200, body=body)
        # signal file return super class _build_response result
        else:
            return super(FtpListingHandler, self)._build_response(
                result, request, protocol)
      
      #+END_SRC
   3. 编写spider爬虫文件 

      此处将登录操作写入到FtpMetaRequest中，每次需要登录下载文件的时候只需要继承该方法即可

      #+BEGIN_SRC 
# -*- coding: utf-8 -*-
import gzip
import json
import os
import time
from scrapy import Request
from scrapy.conf import settings
from scrapy.spiders import CrawlSpider

from ..items import OpensourceThreatIntelItem


class FtpMetaRequest(Request):
    # add user with password to ftp meta request
    user_meta = {'ftp_user': settings['CYREN_FTP_USER'], 'ftp_password': settings['CYREN_FTP_PASS']}

    def __init__(self, args, **kwargs):
        super(FtpMetaRequest, self).__init__(args, **kwargs)
        self.meta.update(self.user_meta)


class FileFtpRequest(FtpMetaRequest):
    pass


class ListFtpRequest(FtpMetaRequest):
    pass


class MedisumSpider(CrawlSpider):
    name = 'cyren.com'

    allowed_domains = [
        "ftp.ctmail.com"
    ]

    def __init__(self):
        self.bak_path = '../data_bak/cyren/'+ self.today_time()+'/'
        if not os.path.exists(self.bak_path):
            os.system('mkdir -p %s ' % self.bak_path)

    def start_requests(self):
        # start request to get all files
        yield ListFtpRequest("ftp://ftp.ctmail.com/ZombieIntelligence/delta/")
        # yield ListFtpRequest("ftp://ftp.ctmail.com/ZombieIntelligence/snapshot/")

    def parse(self, response):
        # get response with all files
        files = json.loads(response.body)
        # file filter not check md5
        files = filter(lambda dic: dic['filename'].endswith('gz')
                       and dic['filename'].find(self.today_time()) >= 0,files)
        for f in files:
            path = os.path.join(response.url, f['filename'])
            filename = self.bak_path + f['filename']
            if os.path.exists(filename):
                self.logger.info('file %s exist ..',f['filename'])
                continue
            self.logger.info('start download %s ..', f['filename'])
            request = FileFtpRequest(path,callback=self.parse_item)
            yield request

    def today_time(self):
        return time.strftime('%y%m%d', time.localtime(time.time()))

    # 解压gz文件
    def un_gz(self,file_name):
        """ungz zip file"""
        f_name = file_name.replace(".gz", "")
        # 获取文件的名称，去掉
        g_file = gzip.GzipFile(file_name)
        # 创建gzip对象
        open(f_name, "w+").write(g_file.read())
        # gzip对象用read()打开后，写入open()建立的文件中。
        g_file.close()
        return f_name

    def ip_format(self,ipstr):
        ip_int = reduce(lambda x,y:(x<<8)+y,map(int,ipstr.split('.')))
        tostr = lambda x: '.'.join([str(x/(256**i)%256) for i in range(3,-1,-1)])
        return tostr(ip_int)

    def parse_item(self, response):
        filename = self.bak_path + response.url.split('/')[-1]
        print filename
        open(filename,'wb').write(response.body)
        self.logger.info('download file  %s ', filename)
        ungz_file = self.un_gz(filename)
        with open(ungz_file, 'r') as ungz:
            os.remove(ungz_file)
            for line in ungz:
                item = OpensourceThreatIntelItem()
                indicator = self.ip_format(line.split(',')[1])
                print indicator
                now_time = time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime(time.time()))
                item['indicator'] = indicator
                item['data_type'] = 0
                item['tag'] = 6
                item['alive'] = True
                item['description'] = line.split(',')[6]
                item['confidence'] = 9
                item['source'] = 'cyren.com'
                item['updated_time'] = line.split(',')[3].replace('-','T').replace('T','-',2)
                item['created_time'] = now_time
                yield item
      
      #+END_SRC

      代码托管位置:[[https://github.com/Nanue1/opensource_threat_intel/tree/master/opensource_threat_intel][github]]

** error note
   1. NotImplementedError
      parse()函数得存在
   2. FTP连接丢失
      调整下载速度可以解决